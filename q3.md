# Cofactor AI MLE Takehome - Part 3
Christian Colella

## Tool Selection

### Medical knowledge bases
* SNOMED CT, ICD-10, RxNorm, LOINC, CDC, WHO - Same data sources as in part 2
* CDC API - Clinical guidelines recommendations

### Patient data integrations
* EHR API connectors - To fetch medical history, lab results, imaging
* FHIR integration - For electronically exchanging health data

### Calculators and code execution
* Medical calculators - For making scientific calculations
* Code execution environment - Custom computations

### Data pre-processors
* Information extraction tools - For parsing information from transcripts
* Section segmenters - Splits raw text into clinical sections

### Search APIs
* Semantic search - Over institutional knowledge bases

This toolkit provides a broad set of skills so that the agent can fetch, calculate, and structure information reliably. It handles transcript parsing, guideline consultation, and computation.

Agentic System Architecture

The system should have the following components:
* Data Extractor Agent - Uses extraction tools to pull structured entities from the transcript
* Orchestrator Agent - Decides which tools to call, when to summarize, and when to validate
* Retriever Agent - Finds and selects relevant knowledge from external knowledge bases or the patient's history
* Computer Agent - Runs calculations, computes doses, performs code as requested by the orchestrator
* Summarizer Agent - Synthesizes information into structured EMR notes
* Validator Agent - Checks for factual correctness and adherence to guidelines
* Traditional Software Components - API interaction, calculations, regex for parsing text

[Flowchart of system architecture](./flowcharts/q3.png)

The tradeoff between LLM vs. non-LLM implementations is capability vs. runtime. LLMs should be used when synthesis and summarization is necessary, and non-LLM tools should be used for entity recognition, calculations, and API interactions.

| Role           | LLM?   | Non-LLM? | Rationale                                                 |
|----------------|--------|----------|-----------------------------------------------------------|
| Data Extractor | Yes/No | Yes      | Prefer deterministic methods where possible               |
| Orchestrator   | Yes    |          | Provides flexible, context-aware workflow control         |
| Retriever      | Yes/No | Yes      | LLM enables flexible search; rule-based ensures precision |
| Computer       |        | Yes      | Ensures precision and safety in computations              |
| Summarizer     | Yes    |          | Natural language generation for EMR notes                 |
| Validator      | Yes/No | Yes      | Ensures clinical QA, coding, and formatting               |

## Evaluation and Optimization

### Metrics
Automatic evaluation involves using metrics such as factual consistency, completeness (coverage of required EMR fields), and coding accuracy (correct use of ICD-10, RxNorm, etc.) to assess system outputs. The system can also automatically compare calculated results against known gold standards to ensure accuracy in quantitative fields.

### Human-in-the-loop evaluation
Periodic review by clinicians ensures that generated EMR notes are accurate, clear, clinically appropriate, and useful for real workflows. Feedback from users through surveys or direct annotation provides valuable insights that may not be captured by automated metrics alone.

### Iterative improvement
By upgrading individual tools (e.g., entity recognition models, calculators), refining prompts and agent policies, and integrating user feedback into the development cycle, the system can adapt and improve over time.

## References
Agentic RAG survey: https://arxiv.org/pdf/2501.09136
CDC API: https://open.cdc.gov/apis.html
FHIR: https://hl7.org/fhir/us/core/